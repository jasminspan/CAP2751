{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "763bQLbzQmw4"
      ]
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p78j872pOKTZ"
      },
      "source": [
        "# CAP 2751 - Tools for Data Science\n",
        "***Include the following info by clicking here:***\n",
        "* Name: Jasmin Spanioli\n",
        "* Canvas Course Section: CAP2751-1\n",
        "* Date: 8/3/2025\n",
        "* Link to your Notebook: https://colab.research.google.com/drive/1ava8yVCXtpKxQy5ez1L31qYU1RCY4yxP?usp=sharing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYmNMHGLOKTa"
      },
      "source": [
        "# Assignment 6: Deep Learning\n",
        "## STARTER CODE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UMnsRndOKTb"
      },
      "source": [
        "### Goals\n",
        "\n",
        "- To learn how to use perform classification using neural networks.\n",
        "- To appreciate the differences in neural network architectures for the same task -- image classification -- and dataset (MNIST, CIFAR-10).\n",
        "- To learn how to implement and evaluate deep learning models in Python, using Keras and TensorFlow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0rEAT7MOKTb"
      },
      "source": [
        "### Instructions\n",
        "\n",
        "- This assignment is structured in 2 parts, each using their own dataset(s).\n",
        "- As usual, there will be some Python code to be written and questions to be answered.\n",
        "- At the end, you should export your notebook to PDF format; it will \"automagically\" become your report.\n",
        "- Submit the report (PDF), notebook (.ipynb file), and the link to the \"live\" version of your solution on Google Colaboratory via Canvas.\n",
        "- **The number of points is indicated next to each part. They add up to 100.**\n",
        "- **There are additional (10 points worth of) bonus items**, which are, of course optional."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiufouQn6OD9"
      },
      "source": [
        "### Important\n",
        "\n",
        "- It is OK to attempt the bonus points, but please **do not overdo it!**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2u-hfaHC-6qb"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efsaBCq-o_rB"
      },
      "source": [
        "### Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1H7CSr4a-6qb"
      },
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XesVDqeGft6C"
      },
      "source": [
        "## PART 1: Digit classification using MNIST\n",
        "\n",
        "The MNIST handwritten digit dataset consists of a training set of 60,000 examples, and a test set of 10,000 examples. Each image in the dataset has 28$\\times$28 pixels.\n",
        "\n",
        "http://yann.lecun.com/exdb/mnist/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEn1cfWJ-6rH"
      },
      "source": [
        "### 1a. Shallow neural network architecture\n",
        "\n",
        "Based on https://github.com/the-deep-learners/deep-learning-illustrated/blob/master/notebooks/shallow_net_in_keras.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxNd2jV5-6qg"
      },
      "source": [
        "#### Load and prepare the data\n",
        "\n",
        "The Python code below loads the images from the MNIST dataset, flattens them, normalizes them (i.e., maps the intensity values from [0..255] to [0..1]), and displays a few images from the training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AL5uSsG5EoEw"
      },
      "source": [
        "# Model / data parameters\n",
        "num_classes = 10\n",
        "input_shape = (28, 28, 1)\n",
        "\n",
        "# the data, split between train and validation sets\n",
        "(X_train, y_train), (X_valid, y_valid) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2jsR31jEqYn"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOXe9zdD-6qp"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99XuEIZf-6qr"
      },
      "source": [
        "y_train[0:12]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rcidoo4X-6qt"
      },
      "source": [
        "plt.figure(figsize=(5,5))\n",
        "for k in range(12):\n",
        "    plt.subplot(3, 4, k+1)\n",
        "    plt.imshow(X_train[k], cmap='Greys')\n",
        "    plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xL2vkR3jO2md"
      },
      "source": [
        "X_valid.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKtAwVhYO34o"
      },
      "source": [
        "y_valid.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rITLTiol7eZH"
      },
      "source": [
        "y_valid[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7wsvxTt7iZO"
      },
      "source": [
        "plt.imshow(X_valid[0], cmap='Greys')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKSraXzh-6qw"
      },
      "source": [
        "# Reshape (flatten) images\n",
        "X_train_reshaped = X_train.reshape(60000, 784).astype('float32')\n",
        "X_valid_reshaped = X_valid.reshape(10000, 784).astype('float32')\n",
        "\n",
        "# Scale images to the [0, 1] range\n",
        "X_train_scaled_reshaped = X_train_reshaped / 255\n",
        "X_valid_scaled_reshaped = X_valid_reshaped / 255\n",
        "\n",
        "# Renaming for conciseness\n",
        "X_training = X_train_scaled_reshaped\n",
        "X_validation = X_valid_scaled_reshaped\n",
        "\n",
        "print(\"X_training shape (after reshaping + scaling):\", X_training.shape)\n",
        "print(X_training.shape[0], \"train samples\")\n",
        "print(\"X_validation shape (after reshaping + scaling):\", X_validation.shape)\n",
        "print(X_validation.shape[0], \"validation samples\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amUBlLnG-6qz"
      },
      "source": [
        "# convert class vectors to binary class matrices\n",
        "y_training = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_validation = tf.keras.utils.to_categorical(y_valid, num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRX6auItPqtX"
      },
      "source": [
        "print(y_valid[0])\n",
        "print(y_validation[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scFSu4nPACnO"
      },
      "source": [
        "#### Build your first neural network model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7CsGuzIKvZd"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(64, activation='sigmoid', input_shape=(784,)))\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQTQzXvJ-6rJ"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0KPx8Di-6rO"
      },
      "source": [
        "(64*784)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7KDBMCS-6rQ"
      },
      "source": [
        "(64*784)+64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ls_u6Lne-6rU"
      },
      "source": [
        "(10*64)+10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eflqPyf9-6rW"
      },
      "source": [
        "#### Configure model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxAxL41M-6rX"
      },
      "source": [
        "model.compile(\n",
        "    loss='mean_squared_error',\n",
        "    optimizer=SGD(learning_rate=0.01),\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DId95CJ_-6rY"
      },
      "source": [
        "#### Train!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGws4yu8-6rZ"
      },
      "source": [
        "batch_size=128\n",
        "epochs=200\n",
        "\n",
        "history = model.fit(\n",
        "  X_training, # training data\n",
        "  y_training, # training targets\n",
        "  epochs=epochs,\n",
        "  batch_size=batch_size,\n",
        "  verbose=1,\n",
        "  validation_data=(X_validation, y_validation)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AJ6owdTR1UA"
      },
      "source": [
        "#### Plot learning curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QF8qu8ByR314"
      },
      "source": [
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "763bQLbzQmw4"
      },
      "source": [
        "#### Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2siGhXrm-6rb"
      },
      "source": [
        "model.evaluate(X_validation, y_validation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vkt05yhuitE_"
      },
      "source": [
        "### 1.1 Your turn! (30 points)\n",
        "\n",
        "1. Write code to train the same network with different options for `loss`, `optimizer`, and learning rate, for example:\n",
        "```\n",
        "model.compile(\n",
        "  optimizer='adam',\n",
        "  loss='categorical_crossentropy',\n",
        "  metrics=['accuracy']\n",
        ")\n",
        "```\n",
        "\n",
        "2. Write code to train the same network with different options for `batch_size` and number of epochs.\n",
        "\n",
        "3. Record the several combinations (at least 3, besides the baseline) you have tried and the resulting accuracy in a summary table like this:\n",
        "\n",
        "| Method | optimizer | learning rate | loss | batch size | epochs | Validation accuracy | Remarks |\n",
        "| --- | --- | --- | --- | --- | --- | --- | --- |\n",
        "| Baseline  | SGD | 0.01 | `mean_squared_error` | 128 | 200 | 0.8660 | Comparable to Naive Bayes |\n",
        "| Variation #1 | ADAM | (default) | `categorical_crossentropy` | 128 | 200 | ... | Improved accuracy thanks to X |\n",
        "| Variation #2 | ... | ... | `categorical_crossentropy` | 128 | 500 | ... | Improved accuracy thanks to Y |\n",
        "| Variation #3 | SGD | 0.01 | `categorical_crossentropy` | 128 | 500 | ... | Improved accuracy thanks to Z |\n",
        "\n",
        "4. Write a short paragraph summarizing what you have learned from this exercise."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a model builder to reuse function"
      ],
      "metadata": {
        "id": "_sfYMk3CYYSg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This function builds and compiles a simple 2-layer neural network\n",
        "# It accepts the optimizer and loss function as arguments\n",
        "def build_model(optimizer, loss_func):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(64, activation='sigmoid', input_shape=(784,)))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    model.compile(optimizer=optimizer, loss=loss_func, metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "Utx2_mBOXey5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train baseline model"
      ],
      "metadata": {
        "id": "jPSJhbN6YgCz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Baseline model with SGD optimizer and mean_squared_error loss\n",
        "baseline_model = build_model(SGD(learning_rate=0.01), 'mean_squared_error')\n",
        "\n",
        "# Train the model for 200 epochs using batch size of 128\n",
        "history_baseline = baseline_model.fit(\n",
        "    X_training, y_training,\n",
        "    epochs=200,\n",
        "    batch_size=128,\n",
        "    validation_data=(X_validation, y_validation),\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "ajeJ3AKfYPu6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train Variation #1"
      ],
      "metadata": {
        "id": "6B1xXf1LY_4v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Variation #1: Use Adam optimizer and categorical_crossentropy loss\n",
        "model_var1 = build_model('adam', 'categorical_crossentropy')\n",
        "\n",
        "# Train with the same batch size and epochs as baseline for fair comparison\n",
        "history_var1 = model_var1.fit(\n",
        "    X_training, y_training,\n",
        "    epochs=200,\n",
        "    batch_size=128,\n",
        "    validation_data=(X_validation, y_validation),\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "id": "K5bKXxH4Y-ao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train Variation #2"
      ],
      "metadata": {
        "id": "u7iUntloZTem"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Variation #2: Same as Variation #1 but train longer\n",
        "model_var2 = build_model('adam', 'categorical_crossentropy')\n",
        "\n",
        "\n",
        "history_var2 = model_var2.fit(\n",
        "    X_training, y_training,\n",
        "    epochs=500, # longer training\n",
        "    batch_size=128,\n",
        "    validation_data=(X_validation, y_validation),\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "id": "WjP8TIPoZWAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train Variation #3"
      ],
      "metadata": {
        "id": "zAE4G3sIZi4U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Variation #3: Use SGD but switch to a better loss function\n",
        "model_var3 = build_model(SGD(learning_rate=0.01), 'categorical_crossentropy')\n",
        "\n",
        "# Keep same extended training time as Variation #2\n",
        "history_var3 = model_var3.fit(\n",
        "    X_training, y_training,\n",
        "    epochs=500,\n",
        "    batch_size=128,\n",
        "    validation_data=(X_validation, y_validation),\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "id": "iQbm9VOuZkbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate"
      ],
      "metadata": {
        "id": "pUi5kAB6ZpOz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the validation accuracy and loss of all models\n",
        "results = {\n",
        "    \"Baseline\": baseline_model.evaluate(X_validation, y_validation, verbose=0),\n",
        "    \"Variation 1\": model_var1.evaluate(X_validation, y_validation, verbose=0),\n",
        "    \"Variation 2\": model_var2.evaluate(X_validation, y_validation, verbose=0),\n",
        "    \"Variation 3\": model_var3.evaluate(X_validation, y_validation, verbose=0)\n",
        "}\n",
        "\n",
        "# Print summary table\n",
        "for name, (loss, acc) in results.items():\n",
        "    print(f\"{name}: Validation Accuracy = {acc:.4f}, Validation Loss = {loss:.4f}\")\n"
      ],
      "metadata": {
        "id": "300xrECyZryc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary\n",
        "  - In this exercise, I experimented with various configurations for training a shallow neural network on the MNIST dataset. I found that switching from mean squared error to categorical crossentropy significantly improved the model's ability to classify digits. And using the Adam optimizer led to faster and more stable convergence compared to SGD. Increasing the number of epochs further improved the model's performance, but at the cost of training time. These experiments highlighted the importance of choosing the right loss function and optimizer in neural network training."
      ],
      "metadata": {
        "id": "E3LqqEO5apy7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C15mmBXeW3ZG"
      },
      "source": [
        "### 1b. Convolutional neural network architecture\n",
        "\n",
        "Based on https://keras.io/examples/vision/mnist_convnet/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyTJv6yKapB9"
      },
      "source": [
        "model_cnn = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=input_shape),\n",
        "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(num_classes, activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model_cnn.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GWxzAaaCqVb"
      },
      "source": [
        "#### Configure model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQhlw1_OaQQx"
      },
      "source": [
        "model_cnn.compile(\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    optimizer=\"adam\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COvZ_7gCEjLc"
      },
      "source": [
        "#### Prepare the data\n",
        "The CNN does not expect the images to be flattened."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPPpaSaUEv-3"
      },
      "source": [
        "# Reload the data, just in case\n",
        "(X_train, y_train), (X_valid, y_valid) = mnist.load_data()\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_training = to_categorical(y_train, num_classes) # Changed keras.utils.np_utils.to_categorical to to_categorical\n",
        "y_validation = to_categorical(y_valid, num_classes) # Changed keras.utils.np_utils.to_categorical to to_categorical\n",
        "\n",
        "# Scale images to the [0, 1] range\n",
        "X_train_cnn = X_train.astype(\"float32\") / 255\n",
        "X_valid_cnn = X_valid.astype(\"float32\") / 255\n",
        "\n",
        "# Redefine  dimension of train/test inputs\n",
        "X_train_cnn = np.expand_dims(X_train_cnn, -1)\n",
        "X_valid_cnn = np.expand_dims(X_valid_cnn, -1)\n",
        "\n",
        "# Make sure images have shape (28, 28, 1)\n",
        "print(\"x_train shape:\", X_train_cnn.shape)\n",
        "print(X_train_cnn.shape[0], \"train samples\")\n",
        "print(X_valid_cnn.shape[0], \"test samples\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqbkD3arDAI4"
      },
      "source": [
        "#### Train!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1i6Pypg0C4Jq"
      },
      "source": [
        "batch_size=128\n",
        "epochs=15\n",
        "\n",
        "history = model_cnn.fit(\n",
        "  X_train_cnn, # training data\n",
        "  y_training, # training targets\n",
        "  epochs=epochs,\n",
        "  batch_size=batch_size,\n",
        "  verbose=1,\n",
        "  validation_data=(X_valid_cnn, y_validation)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uHN4KNdDC1T"
      },
      "source": [
        "#### Plot learning curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUdOrMVHDGIa"
      },
      "source": [
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oP7csjo2DGag"
      },
      "source": [
        "#### Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W86Hi07fDICp"
      },
      "source": [
        "model_cnn.evaluate(X_valid_cnn, y_validation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoqCtgxJDwft"
      },
      "source": [
        "### 1.2 Your turn! (30 points)\n",
        "\n",
        "1. Write code to train the same network with different options for `loss`, `optimizer`, learning rate,  `batch_size` and number of epochs.\n",
        "\n",
        "2. Record the several combinations (at least 3, besides the baseline) you have tried and the resulting accuracy in a summary table similar to the one for item 1.1.\n",
        "\n",
        "3. Write a short paragraph summarizing what you have learned from this exercise."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build a CNN model function"
      ],
      "metadata": {
        "id": "KbdLZH3Ra-z4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to build a CNN with given loss and optimizer\n",
        "def build_cnn_model(optimizer, loss_func):\n",
        "    model = keras.Sequential([\n",
        "        keras.Input(shape=(28, 28, 1)),\n",
        "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(num_classes, activation=\"softmax\"),\n",
        "    ])\n",
        "    model.compile(optimizer=optimizer, loss=loss_func, metrics=[\"accuracy\"])\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "vTSimPKObDVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare Data for CNN"
      ],
      "metadata": {
        "id": "ZSUiLj3TbON4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reload data for CNN\n",
        "\n",
        "(X_train, y_train), (X_valid, y_valid) = mnist.load_data()\n",
        "\n",
        "# Convert labels to one hot encoded vectors\n",
        "y_training = to_categorical(y_train, num_classes)\n",
        "y_validation = to_categorical(y_valid, num_classes)\n",
        "\n",
        "# Normalize and reshape input data for CNN\n",
        "X_train_cnn = np.expand_dims(X_train.astype(\"float32\") / 255, -1)\n",
        "X_valid_cnn = np.expand_dims(X_valid.astype(\"float32\") / 255, -1)\n",
        "\n",
        "print(\"x_train shape:\", X_train_cnn.shape)\n",
        "print(X_train_cnn.shape[0], \"train samples\")\n",
        "print(X_valid_cnn.shape[0], \"validation samples\")\n"
      ],
      "metadata": {
        "id": "pwXFAEXnbRUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train Baseline CNN"
      ],
      "metadata": {
        "id": "ttkw0zc_bZeP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train baseline CNN using Adam optimizer and categorical_crossentropy loss\n",
        "cnn_baseline = build_cnn_model('adam', 'categorical_crossentropy')\n",
        "\n",
        "history_baseline = cnn_baseline.fit(\n",
        "    X_train_cnn, y_training,\n",
        "    epochs=15,\n",
        "    batch_size=128,\n",
        "    validation_data=(X_valid_cnn, y_validation),\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "id": "diZx3l-Rbcd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Variation #1"
      ],
      "metadata": {
        "id": "WuXX3yPobeWb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use SGD optimizer with same loss\n",
        "cnn_var1 = build_cnn_model(SGD(learning_rate=0.01), 'categorical_crossentropy')\n",
        "\n",
        "history_var1 = cnn_var1.fit(\n",
        "    X_train_cnn, y_training,\n",
        "    epochs=15,\n",
        "    batch_size=128,\n",
        "    validation_data=(X_valid_cnn, y_validation),\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "fxxkeG7gbm_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Variation #2"
      ],
      "metadata": {
        "id": "rX3zchTDbpVQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use more training epochs with baseline optimizer and loss\n",
        "cnn_var2 = build_cnn_model('adam', 'categorical_crossentropy')\n",
        "\n",
        "history_var2 = cnn_var2.fit(\n",
        "    X_train_cnn, y_training,\n",
        "    epochs=30,  # longer training\n",
        "    batch_size=128,\n",
        "    validation_data=(X_valid_cnn, y_validation),\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "rrWhuGl8bsX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Variation #3"
      ],
      "metadata": {
        "id": "jjYcJxFob66N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Smaller batch size may help model converge differently\n",
        "cnn_var3 = build_cnn_model('adam', 'categorical_crossentropy')\n",
        "\n",
        "history_var3 = cnn_var3.fit(\n",
        "    X_train_cnn, y_training,\n",
        "    epochs=15,\n",
        "    batch_size=64,  # smaller batch\n",
        "    validation_data=(X_valid_cnn, y_validation),\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "id": "vTueVNY-b-r1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate"
      ],
      "metadata": {
        "id": "vrQF425kcHsb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate all 4 models on the validation set\n",
        "results_cnn = {\n",
        "    \"Baseline\": cnn_baseline.evaluate(X_valid_cnn, y_validation, verbose=0),\n",
        "    \"Var1\": cnn_var1.evaluate(X_valid_cnn, y_validation, verbose=0),\n",
        "    \"Var2\": cnn_var2.evaluate(X_valid_cnn, y_validation, verbose=0),\n",
        "    \"Var3\": cnn_var3.evaluate(X_valid_cnn, y_validation, verbose=0)\n",
        "}\n",
        "\n",
        "# Print comparison results\n",
        "for name, (loss, acc) in results_cnn.items():\n",
        "    print(f\"{name}: Validation Accuracy = {acc:.4f}, Validation Loss = {loss:.4f}\")\n"
      ],
      "metadata": {
        "id": "RQzbF6zLcIlQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CNN Model Summary Table\n",
        "\n",
        "| Method        | Optimizer | Learning Rate | Loss                  | Batch Size | Epochs | Val Accuracy | Remarks                      |\n",
        "|---------------|-----------|----------------|------------------------|------------|--------|---------------|------------------------------|\n",
        "| Baseline      | Adam      | default         | categorical_crossentropy | 128        | 15     | 0.9919xx        | High accuracy, fast converge |\n",
        "| Variation #1  | SGD       | 0.01            | categorical_crossentropy | 128        | 15     | 0.9757xx        | Slower but stable            |\n",
        "| Variation #2  | Adam      | default         | categorical_crossentropy | 128        | 30     | 0.9939xx        | Best result with more epochs |\n",
        "| Variation #3  | Adam      | default         | categorical_crossentropy | 64         | 15     | 0.9932xx        | Slight improvement w/ smaller batch |\n",
        "\n",
        "\n",
        "\n",
        "In this exercise, I learned that convolutional networks benefit from adaptive optimizers like Adam and longer training. The CNN outperformed the shallow model from Part 1.1. Increasing the number of epochs and adjusting batch size helped fine-tune accuracy. SGD worked but took longer to converge. Overall, CNNs are more powerful and flexible for image recognition.\n"
      ],
      "metadata": {
        "id": "bPkEZZoCcoaO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUhUYhtHEM1F"
      },
      "source": [
        "### 1.3 BONUS! (10 points)\n",
        "\n",
        "1. Change the architecture of the CNN (number of layers, use of (and amount of) Dropout,  conv2D layers' [parameters](https://keras.io/api/layers/convolution_layers/convolution2d/) (stride, padding, kernel size, etc.), type and parameters of [pooling layers](https://https://keras.io/api/layers/pooling_layers/), etc.)\n",
        "\n",
        "2. Record the several combinations (at least 3, besides the baseline) you have tried and the resulting accuracy in a summary table similar to the one for item 1.1.\n",
        "\n",
        "3. Write a short paragraph summarizing what you have learned from this exercise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KT9ZKo3q-2-F"
      },
      "source": [
        "## PART 2: Image classification using the CIFAR-10 dataset\n",
        "  \n",
        "In this project you will design and implement a deep learning solution for image classification using the CIFAR-10 dataset.\n",
        "\n",
        "https://www.cs.toronto.edu/~kriz/cifar.html\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPc4CuJc--cX"
      },
      "source": [
        "See also:\n",
        "\n",
        "https://www.kaggle.com/c/cifar-10\n",
        "\n",
        "https://keras.io/examples/vision/metric_learning/\n",
        "\n",
        "https://www.kaggle.com/roblexnana/cifar10-with-cnn-for-beginer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gt7GMeCa_AvJ"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-ekROtVJgPu"
      },
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "# The import path was changed here from `keras.preprocessing.image` to `tensorflow.keras.preprocessing.image`\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import itertools\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import random\n",
        "\n",
        "import tensorflow as tf\n",
        "from collections import defaultdict\n",
        "from PIL import Image\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73qugU8N_DeA"
      },
      "source": [
        "### Load and prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjoEgfXAvps9"
      },
      "source": [
        "# Load the dataset\n",
        "(x_training, y_training), (x_testing, y_testing) = cifar10.load_data()\n",
        "\n",
        "# Normalize the image data\n",
        "x_train = x_training.astype(\"float32\") / 255.0\n",
        "y_training = np.squeeze(y_training)\n",
        "x_test = x_testing.astype(\"float32\") / 255.0\n",
        "y_testing = np.squeeze(y_testing)\n",
        "\n",
        "# Convert class vectors to binary class matrices (one-hot encoding)\n",
        "y_train = keras.utils.to_categorical(y_training, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_testing, num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKKCkNYJ_HJV"
      },
      "source": [
        "### Explore the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtIfVbzeGSOV"
      },
      "source": [
        "# Number of samples\n",
        "print(\"Number of training samples: \",y_train.shape[0])\n",
        "print(\"Number of test samples: \", y_test.shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYPWP2kU9iYB"
      },
      "source": [
        "# Number of classes\n",
        "num_classes = y_test.shape[1]\n",
        "print(num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pylQgSDEGiUW"
      },
      "source": [
        "# Shape of image data\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fWRJPHXFMYT"
      },
      "source": [
        "# Show collage of 25 (randomly selected) images\n",
        "\n",
        "# Every time you run this cell, you should see 25 different images.\n",
        "# That's fine (and desired, actually).\n",
        "\n",
        "height_width = 32\n",
        "\n",
        "def show_collage(examples):\n",
        "    box_size = height_width + 2\n",
        "    num_rows, num_cols = examples.shape[:2]\n",
        "\n",
        "    collage = Image.new(\n",
        "        mode=\"RGB\",\n",
        "        size=(num_cols * box_size, num_rows * box_size),\n",
        "        color=(250, 250, 250),\n",
        "    )\n",
        "    for row_idx in range(num_rows):\n",
        "        for col_idx in range(num_cols):\n",
        "            array = (np.array(examples[row_idx, col_idx]) * 255).astype(np.uint8)\n",
        "            collage.paste(\n",
        "                Image.fromarray(array), (col_idx * box_size, row_idx * box_size)\n",
        "            )\n",
        "\n",
        "    # Double size for visualisation.\n",
        "    collage = collage.resize((2 * num_cols * box_size, 2 * num_rows * box_size))\n",
        "    return collage\n",
        "\n",
        "\n",
        "# Show a collage of 5x5 random images.\n",
        "sample_idxs = np.random.randint(0, 50000, size=(5, 5))\n",
        "examples = x_train[sample_idxs]\n",
        "show_collage(examples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UBNAMEFhpO-"
      },
      "source": [
        "idx = y_training[0]\n",
        "print(idx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-Ounsgugy62"
      },
      "source": [
        "y_train[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVVy55aRh9WH"
      },
      "source": [
        "labels = ['Airplane', 'Automobile', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFNcrdIMh-0q"
      },
      "source": [
        "labels[idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7C1yFWDgI8V"
      },
      "source": [
        "plt.imshow(x_train[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ko85MBf3_PLo"
      },
      "source": [
        "### 2a. Baseline model\n",
        "\n",
        "Let's start by using a convolutional neural network (CNN) built from scratch as a baseline.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-Zm6TrWJAa7"
      },
      "source": [
        "#### Build and configure the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gy5UaNEJJKPY"
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 40\n",
        "data_augmentation = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BimauqBJJxOq"
      },
      "source": [
        "#define the convnet\n",
        "model = Sequential()\n",
        "# CONV => RELU => CONV => RELU => POOL => DROPOUT\n",
        "model.add(Conv2D(32, (3, 3), padding='same',input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# CONV => RELU => CONV => RELU => POOL => DROPOUT\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# FLATTEN => DENSE => RELU => DROPOUT\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "# a softmax classifier\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IPu039hEAzk"
      },
      "source": [
        "# initiate RMSprop optimizer\n",
        "opt = keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6)\n",
        "\n",
        "# Let's train the model using RMSprop\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oG1aHr4Y_Xej"
      },
      "source": [
        "#### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hd_INlX1J12V",
        "outputId": "4b42f576-8778-4089-daae-e490b1b27cd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1727
        }
      },
      "source": [
        "history = model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 25ms/step - accuracy: 0.1931 - loss: 2.1407 - val_accuracy: 0.3459 - val_loss: 1.8301\n",
            "Epoch 2/40\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.3514 - loss: 1.7815 - val_accuracy: 0.4231 - val_loss: 1.6160\n",
            "Epoch 3/40\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.4068 - loss: 1.6510 - val_accuracy: 0.4416 - val_loss: 1.5693\n",
            "Epoch 4/40\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.4386 - loss: 1.5551 - val_accuracy: 0.4737 - val_loss: 1.4433\n",
            "Epoch 5/40\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.4624 - loss: 1.4786 - val_accuracy: 0.5012 - val_loss: 1.3860\n",
            "Epoch 6/40\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.4876 - loss: 1.4121 - val_accuracy: 0.5270 - val_loss: 1.3088\n",
            "Epoch 7/40\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.5160 - loss: 1.3555 - val_accuracy: 0.5442 - val_loss: 1.2823\n",
            "Epoch 8/40\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.5323 - loss: 1.3171 - val_accuracy: 0.5760 - val_loss: 1.2118\n",
            "Epoch 9/40\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.5493 - loss: 1.2738 - val_accuracy: 0.5902 - val_loss: 1.1668\n",
            "Epoch 10/40\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.5664 - loss: 1.2245 - val_accuracy: 0.5870 - val_loss: 1.1757\n",
            "Epoch 11/40\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.5723 - loss: 1.2057 - val_accuracy: 0.6002 - val_loss: 1.1495\n",
            "Epoch 12/40\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.5876 - loss: 1.1647 - val_accuracy: 0.6031 - val_loss: 1.1280\n",
            "Epoch 13/40\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.6015 - loss: 1.1238 - val_accuracy: 0.6321 - val_loss: 1.0530\n",
            "Epoch 14/40\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.6126 - loss: 1.1018 - val_accuracy: 0.6417 - val_loss: 1.0244\n",
            "Epoch 15/40\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.6220 - loss: 1.0705 - val_accuracy: 0.6449 - val_loss: 1.0204\n",
            "Epoch 16/40\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.6302 - loss: 1.0508 - val_accuracy: 0.6590 - val_loss: 0.9764\n",
            "Epoch 17/40\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.6406 - loss: 1.0267 - val_accuracy: 0.6577 - val_loss: 0.9819\n",
            "Epoch 18/40\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.6404 - loss: 1.0178 - val_accuracy: 0.6694 - val_loss: 0.9463\n",
            "Epoch 19/40\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.6514 - loss: 0.9959 - val_accuracy: 0.6687 - val_loss: 0.9405\n",
            "Epoch 20/40\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.6625 - loss: 0.9726 - val_accuracy: 0.6806 - val_loss: 0.9143\n",
            "Epoch 21/40\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.6661 - loss: 0.9495 - val_accuracy: 0.6763 - val_loss: 0.9218\n",
            "Epoch 22/40\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.6695 - loss: 0.9418 - val_accuracy: 0.6910 - val_loss: 0.8886\n",
            "Epoch 23/40\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.6708 - loss: 0.9310 - val_accuracy: 0.6990 - val_loss: 0.8631\n",
            "Epoch 24/40\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.6845 - loss: 0.9083 - val_accuracy: 0.6962 - val_loss: 0.8667\n",
            "Epoch 25/40\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.6848 - loss: 0.8907 - val_accuracy: 0.6988 - val_loss: 0.8557\n",
            "Epoch 26/40\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.6965 - loss: 0.8734 - val_accuracy: 0.7018 - val_loss: 0.8500\n",
            "Epoch 27/40\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.6973 - loss: 0.8636 - val_accuracy: 0.6985 - val_loss: 0.8516\n",
            "Epoch 28/40\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.7042 - loss: 0.8466 - val_accuracy: 0.7079 - val_loss: 0.8336\n",
            "Epoch 29/40\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.7085 - loss: 0.8336 - val_accuracy: 0.7165 - val_loss: 0.8033\n",
            "Epoch 30/40\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.7103 - loss: 0.8282 - val_accuracy: 0.7213 - val_loss: 0.8017\n",
            "Epoch 31/40\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.7143 - loss: 0.8167 - val_accuracy: 0.7235 - val_loss: 0.7930\n",
            "Epoch 32/40\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.7214 - loss: 0.7970 - val_accuracy: 0.7219 - val_loss: 0.8007\n",
            "Epoch 33/40\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.7240 - loss: 0.7838 - val_accuracy: 0.7194 - val_loss: 0.7974\n",
            "Epoch 34/40\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.7257 - loss: 0.7836 - val_accuracy: 0.7272 - val_loss: 0.7836\n",
            "Epoch 35/40\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.7337 - loss: 0.7653 - val_accuracy: 0.7292 - val_loss: 0.7753\n",
            "Epoch 36/40\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.7381 - loss: 0.7558 - val_accuracy: 0.7300 - val_loss: 0.7781\n",
            "Epoch 37/40\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.7385 - loss: 0.7500 - val_accuracy: 0.7369 - val_loss: 0.7536\n",
            "Epoch 38/40\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.7426 - loss: 0.7340 - val_accuracy: 0.7443 - val_loss: 0.7392\n",
            "Epoch 39/40\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.7469 - loss: 0.7275 - val_accuracy: 0.7406 - val_loss: 0.7488\n",
            "Epoch 40/40\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3304761206.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(x_train, y_train,\n\u001b[0m\u001b[1;32m      2\u001b[0m               \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m               shuffle=True)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/callback_list.py\u001b[0m in \u001b[0;36mon_train_batch_begin\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkbojRWfcRKm"
      },
      "source": [
        "def plotmodelhistory(history):\n",
        "    fig, axs = plt.subplots(1,2,figsize=(15,5))\n",
        "    # summarize history for accuracy\n",
        "    axs[0].plot(history.history['accuracy'])\n",
        "    axs[0].plot(history.history['val_accuracy'])\n",
        "    axs[0].set_title('Model Accuracy')\n",
        "    axs[0].set_ylabel('Accuracy')\n",
        "    axs[0].set_xlabel('Epoch')\n",
        "    axs[0].legend(['train', 'validate'], loc='upper left')\n",
        "    # summarize history for loss\n",
        "    axs[1].plot(history.history['loss'])\n",
        "    axs[1].plot(history.history['val_loss'])\n",
        "    axs[1].set_title('Model Loss')\n",
        "    axs[1].set_ylabel('Loss')\n",
        "    axs[1].set_xlabel('Epoch')\n",
        "    axs[1].legend(['train', 'validate'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "# list all data in history\n",
        "print(history.history.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGDXkeulolBX"
      },
      "source": [
        "plotmodelhistory(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0t9j0PpH_cHU"
      },
      "source": [
        "#### Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlGqHnOgLseg"
      },
      "source": [
        "# Score trained model.\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])\n",
        "\n",
        "# make prediction.\n",
        "pred = model.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y05-z_POcfn9"
      },
      "source": [
        "def heatmap(data, row_labels, col_labels, ax=None, cbar_kw={}, cbarlabel=\"\", **kwargs):\n",
        "    \"\"\"\n",
        "    Create a heatmap from a numpy array and two lists of labels.\n",
        "    \"\"\"\n",
        "    if not ax:\n",
        "        ax = plt.gca()\n",
        "\n",
        "    # Plot the heatmap\n",
        "    im = ax.imshow(data, **kwargs)\n",
        "\n",
        "    # Create colorbar\n",
        "    cbar = ax.figure.colorbar(im, ax=ax, **cbar_kw)\n",
        "    cbar.ax.set_ylabel(cbarlabel, rotation=-90, va=\"bottom\")\n",
        "\n",
        "    # Let the horizontal axes labeling appear on top.\n",
        "    ax.tick_params(top=True, bottom=False,\n",
        "                   labeltop=True, labelbottom=False)\n",
        "    # We want to show all ticks...\n",
        "    ax.set_xticks(np.arange(data.shape[1]))\n",
        "    ax.set_yticks(np.arange(data.shape[0]))\n",
        "    # ... and label them with the respective list entries.\n",
        "    ax.set_xticklabels(col_labels)\n",
        "    ax.set_yticklabels(row_labels)\n",
        "\n",
        "    ax.set_xlabel('Predicted Label')\n",
        "    ax.set_ylabel('True Label')\n",
        "\n",
        "    return im, cbar\n",
        "\n",
        "def annotate_heatmap(im, data=None, fmt=\"d\", threshold=None):\n",
        "    \"\"\"\n",
        "    A function to annotate a heatmap.\n",
        "    \"\"\"\n",
        "    # Change the text's color depending on the data.\n",
        "    texts = []\n",
        "    for i in range(data.shape[0]):\n",
        "        for j in range(data.shape[1]):\n",
        "            text = im.axes.text(j, i, format(data[i, j], fmt), horizontalalignment=\"center\",\n",
        "                                 color=\"white\" if data[i, j] > thresh else \"black\")\n",
        "            texts.append(text)\n",
        "\n",
        "    return texts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGpFemIkCs-O"
      },
      "source": [
        "# Plot confusion matrix\n",
        "\n",
        "# Convert predictions classes to one hot vectors\n",
        "Y_pred_classes = np.argmax(pred, axis=1)\n",
        "# Convert validation observations to one hot vectors\n",
        "Y_true = np.argmax(y_test, axis=1)\n",
        "# Errors are difference between predicted labels and true labels\n",
        "errors = (Y_pred_classes - Y_true != 0)\n",
        "\n",
        "Y_pred_classes_errors = Y_pred_classes[errors]\n",
        "Y_pred_errors = pred[errors]\n",
        "Y_true_errors = Y_true[errors]\n",
        "X_test_errors = x_test[errors]\n",
        "\n",
        "cm = confusion_matrix(Y_true, Y_pred_classes)\n",
        "thresh = cm.max() / 2.\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12,12))\n",
        "im, cbar = heatmap(cm, labels, labels, ax=ax,\n",
        "                   cmap=plt.cm.Blues, cbarlabel=\"count of predictions\")\n",
        "texts = annotate_heatmap(im, data=cm, threshold=thresh)\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qX5x9GeIcsFf"
      },
      "source": [
        "print(classification_report(Y_true, Y_pred_classes))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqsg3jiHeeuw"
      },
      "source": [
        "# Inspect errors\n",
        "R = 3\n",
        "C = 5\n",
        "fig, axes = plt.subplots(R, C, figsize=(12,8))\n",
        "axes = axes.ravel()\n",
        "\n",
        "misclassified_idx = np.where(Y_pred_classes != Y_true)[0]\n",
        "for i in np.arange(0, R*C):\n",
        "    axes[i].imshow(x_test[misclassified_idx[i]])\n",
        "    axes[i].set_title(\"True: %s \\nPredicted: %s\" % (labels[Y_true[misclassified_idx[i]]],\n",
        "                                                  labels[Y_pred_classes[misclassified_idx[i]]]))\n",
        "    axes[i].axis('off')\n",
        "    plt.subplots_adjust(wspace=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zcnah74Xeso1"
      },
      "source": [
        "def show_test(number):\n",
        "    fig = plt.figure(figsize = (3,3))\n",
        "    test_image = np.expand_dims(x_test[number], axis=0)\n",
        "    # test_result = model.predict_classes(test_image)\n",
        "    test_result = np.argmax(model.predict(test_image), axis=-1)\n",
        "    plt.imshow(x_test[number])\n",
        "    dict_key = test_result[0]\n",
        "    plt.title(\"Predicted: {} \\nTrue Label: {}\".format(labels[dict_key],\n",
        "                                                      labels[Y_true[number]]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAueRSxUeuNG"
      },
      "source": [
        "show_test(11)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZbSSCWiBnIp"
      },
      "source": [
        "### 2b. Transfer Learning\n",
        "\n",
        "Now we will see how we could use a [pretrained (on ImageNet) model](https://https://keras.io/api/applications/) to perform the same task (image classification) using a different dataset (CIFAR-10), using the *transfer learning* paradigm.\n",
        "\n",
        "See:\n",
        "\n",
        "https://www.kaggle.com/adi160/cifar-10-keras-transfer-learning\n",
        "\n",
        "https://keras.io/guides/transfer_learning/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EM0vEucQy4k-"
      },
      "source": [
        "#### Transfer Learning: setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNFnPmV4BpKL"
      },
      "source": [
        "from keras import Sequential\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.resnet import ResNet50\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator # Changed import here\n",
        "from tensorflow.keras.optimizers import SGD,Adam\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.layers import Flatten,Dense,BatchNormalization,Activation,Dropout\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izdwD8kDmaVh"
      },
      "source": [
        "#Import dataset (again)\n",
        "(x_train,y_train),(x_test,y_test)=cifar10.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isiCh_Mkmfqa"
      },
      "source": [
        "x_train,x_val,y_train,y_val=train_test_split(x_train,y_train,test_size=.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "my5Tdzewm4K_"
      },
      "source": [
        "#Print the dimensions of the datasets to make sure everything's kosher\n",
        "\n",
        "print((x_train.shape,y_train.shape))\n",
        "print((x_val.shape,y_val.shape))\n",
        "print((x_test.shape,y_test.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRku9Ktom9Lj"
      },
      "source": [
        "#One hot encode the labels.Since we have 10 classes we should expect the shape[1] of y_train,y_val and y_test to change from 1 to 10\n",
        "\n",
        "y_train=to_categorical(y_train)\n",
        "y_val=to_categorical(y_val)\n",
        "y_test=to_categorical(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTbSc_EpnBLS"
      },
      "source": [
        "# Lets print the dimensions one more time to see if things changed the way we expected\n",
        "\n",
        "print((x_train.shape,y_train.shape))\n",
        "print((x_val.shape,y_val.shape))\n",
        "print((x_test.shape,y_test.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RrjI9sPy8dR"
      },
      "source": [
        "#### Attempt #1: using ResNet50 as a base model\n",
        "\n",
        "Learn more about ResNet50 at: https://www.kaggle.com/keras/resnet50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbuuBH8BmOox"
      },
      "source": [
        "base_model_1 = ResNet50(include_top=False,\n",
        "                        weights='imagenet',\n",
        "                        input_shape=(32,32,3),\n",
        "                        classes=y_train.shape[1])\n",
        "\n",
        "model_1=Sequential()\n",
        "#Add the Dense layers along with activation and batch normalization\n",
        "model_1.add(base_model_1)\n",
        "model_1.add(Flatten())\n",
        "\n",
        "#Add the Dense layers along with activation and batch normalization\n",
        "model_1.add(Dense(4000,activation=('relu'),input_dim=512))\n",
        "model_1.add(Dense(2000,activation=('relu')))\n",
        "model_1.add(Dense(1000,activation=('relu')))\n",
        "model_1.add(Dense(500,activation=('relu')))\n",
        "model_1.add(Dense(10,activation=('softmax'))) #This is the classification layer\n",
        "\n",
        "model_1.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Qlj84Ycnqi0"
      },
      "source": [
        "batch_size= 128\n",
        "epochs=10\n",
        "learn_rate=.001\n",
        "\n",
        "sgd=SGD(learning_rate=learn_rate,momentum=.9,nesterov=False)\n",
        "adam=Adam(learning_rate=learn_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4HB_d_4n4uw"
      },
      "source": [
        "# Compile the model\n",
        "model_1.compile(optimizer=sgd,\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Am2eK3x-n91w"
      },
      "source": [
        "# Train the model\n",
        "history_1 = model_1.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              verbose = 1,\n",
        "              validation_data=(x_val, y_val),\n",
        "              shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3e3pVZQyH-D"
      },
      "source": [
        "def plotmodelhistory(history):\n",
        "    fig, axs = plt.subplots(1,2,figsize=(15,5))\n",
        "    # summarize history for accuracy\n",
        "    axs[0].plot(history.history['accuracy'])\n",
        "    axs[0].plot(history.history['val_accuracy'])\n",
        "    axs[0].set_title('Model Accuracy')\n",
        "    axs[0].set_ylabel('Accuracy')\n",
        "    axs[0].set_xlabel('Epoch')\n",
        "    axs[0].legend(['train', 'validate'], loc='upper left')\n",
        "    # summarize history for loss\n",
        "    axs[1].plot(history.history['loss'])\n",
        "    axs[1].plot(history.history['val_loss'])\n",
        "    axs[1].set_title('Model Loss')\n",
        "    axs[1].set_ylabel('Loss')\n",
        "    axs[1].set_xlabel('Epoch')\n",
        "    axs[1].legend(['train', 'validate'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "# list all data in history\n",
        "print(history_1.history.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noc2gSxbyOeN"
      },
      "source": [
        "plotmodelhistory(history_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBsL-iLZoKtq"
      },
      "source": [
        "# Score trained model.\n",
        "scores = model_1.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])\n",
        "\n",
        "# make prediction.\n",
        "pred = model_1.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ans07phrLAX"
      },
      "source": [
        "  def plot_confusion_matrix(y_true, y_pred, classes,\n",
        "                          normalize=False,\n",
        "                          title=None,\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if not title:\n",
        "        if normalize:\n",
        "            title = 'Normalized confusion matrix'\n",
        "        else:\n",
        "            title = 'Confusion matrix, without normalization'\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "#     print(cm)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(7,7))\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    # We want to show all ticks...\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           # ... and label them with the respective list entries\n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           title=title,\n",
        "           ylabel='True label',\n",
        "           xlabel='Predicted label')\n",
        "\n",
        "    # Rotate the tick labels and set their alignment.\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "             rotation_mode=\"anchor\")\n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "    return ax\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXT0_WK4swKo"
      },
      "source": [
        "y_pred = np.argmax(model_1.predict(x_test), axis=-1)\n",
        "y_true=np.argmax(y_test,axis=1)\n",
        "\n",
        "#Compute the confusion matrix\n",
        "confusion_mtx=confusion_matrix(y_true,y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nvF1UQ-syv2"
      },
      "source": [
        "# Plot non-normalized confusion matrix\n",
        "plot_confusion_matrix(y_true, y_pred, classes=labels,\n",
        "                      title='Confusion matrix, without normalization')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dE_wN_FKs3Du"
      },
      "source": [
        "# Plot normalized confusion matrix\n",
        "plot_confusion_matrix(y_true, y_pred, classes=labels, normalize=True,\n",
        "                      title='Normalized confusion matrix')\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoP0dMzTzMlI"
      },
      "source": [
        "### 2.1 Your turn! (30 points)\n",
        "\n",
        "1. Write code to build, train, and evaluate at least three additional transfer learning models and combinations of (hyper)parameters.\n",
        "\n",
        "Here are a few things you could do:\n",
        "*   Use a different base model, e.g., VGG19 (see https://www.kaggle.com/keras/vgg19)\n",
        "*   Add Dropout layers\n",
        "*   Use data augmentation\n",
        "*   Change optimizer\n",
        "*   Change other hyperparameters (learning rate, batch size, etc.)\n",
        "\n",
        "2. Record the several combinations (at least 3, besides the baseline) you have tried and the resulting accuracy in a summary table like this:\n",
        "\n",
        "| Method | Base model | Relevant (hyper)parameters | Test loss | Test accuracy | Remarks |\n",
        "| --- | --- | --- | --- | --- | --- |\n",
        "| Baseline  | ResNet50 | SGD, batch_size= 128, epochs=10, learn_rate=.001 | 1.2025 | 0.7526 | Baseline |\n",
        "| Variation #1 | ... | ... | ... | ... | Improved accuracy thanks to X |\n",
        "| Variation #2 | ... | ... | ... | ... | Improved accuracy thanks to Y |\n",
        "| Variation #3 | ... | ... | ... | ... | Improved accuracy thanks to Z |\n",
        "\n",
        "3. Write a short paragraph summarizing what you have learned from this exercise.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Variation #1"
      ],
      "metadata": {
        "id": "RgkM8w3QeUNX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build and compile the VGG19 transfer learning model"
      ],
      "metadata": {
        "id": "PGj_vB9tdbQ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.datasets import cifar10\n",
        "\n",
        "# Load data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Normalize input\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "\n",
        "# One-hot encode labels\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Split training into train + validation\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.3)\n",
        "\n",
        "# Build VGG19 base model\n",
        "base_model_vgg19 = VGG19(include_top=False, weights='imagenet', input_shape=(32, 32, 3))\n",
        "\n",
        "# Build transfer learning model\n",
        "model_vgg19 = Sequential()\n",
        "model_vgg19.add(base_model_vgg19)\n",
        "model_vgg19.add(Flatten())\n",
        "\n",
        "# Add dense layers with dropout\n",
        "model_vgg19.add(Dense(512, activation='relu'))\n",
        "model_vgg19.add(Dropout(0.5))\n",
        "model_vgg19.add(Dense(256, activation='relu'))\n",
        "model_vgg19.add(Dropout(0.3))\n",
        "model_vgg19.add(Dense(10, activation='softmax'))  # Output layer\n",
        "\n",
        "# Compile with Adam optimizer\n",
        "model_vgg19.compile(optimizer=Adam(learning_rate=0.0001),\n",
        "                    loss='categorical_crossentropy',\n",
        "                    metrics=['accuracy'])\n",
        "\n",
        "# Display model structure\n",
        "model_vgg19.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "v7WDiZaNdeCQ",
        "outputId": "478c1b59-11e1-4090-aee4-28d6cdbdca74"
      },
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_21\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_21\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ vgg19 (\u001b[38;5;33mFunctional\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │    \u001b[38;5;34m20,024,384\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_10 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_37 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_14 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_38 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_15 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_39 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m2,570\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ vgg19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">20,024,384</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,570</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m20,420,938\u001b[0m (77.90 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,420,938</span> (77.90 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m20,420,938\u001b[0m (77.90 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,420,938</span> (77.90 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train"
      ],
      "metadata": {
        "id": "tVEpj5iHdjR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history_vgg19 = model_vgg19.fit(\n",
        "    x_train, y_train,\n",
        "    batch_size=128,\n",
        "    epochs=10,\n",
        "    validation_data=(x_val, y_val),\n",
        "    shuffle=True,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "uFJb9ta0dkf2",
        "outputId": "f31ed539-42ed-4cf6-92bf-452501438652"
      },
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 126ms/step - accuracy: 0.3384 - loss: 1.8195 - val_accuracy: 0.7027 - val_loss: 0.8842\n",
            "Epoch 2/10\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 103ms/step - accuracy: 0.7328 - loss: 0.8272 - val_accuracy: 0.7785 - val_loss: 0.6636\n",
            "Epoch 3/10\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 102ms/step - accuracy: 0.8068 - loss: 0.5969 - val_accuracy: 0.7923 - val_loss: 0.6350\n",
            "Epoch 4/10\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 102ms/step - accuracy: 0.8463 - loss: 0.4743 - val_accuracy: 0.8259 - val_loss: 0.5410\n",
            "Epoch 5/10\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 109ms/step - accuracy: 0.8811 - loss: 0.3683 - val_accuracy: 0.8289 - val_loss: 0.5226\n",
            "Epoch 6/10\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 109ms/step - accuracy: 0.9109 - loss: 0.2826 - val_accuracy: 0.8362 - val_loss: 0.5602\n",
            "Epoch 7/10\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 110ms/step - accuracy: 0.9274 - loss: 0.2269 - val_accuracy: 0.8268 - val_loss: 0.6046\n",
            "Epoch 8/10\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 109ms/step - accuracy: 0.9416 - loss: 0.1901 - val_accuracy: 0.8359 - val_loss: 0.5974\n",
            "Epoch 9/10\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 109ms/step - accuracy: 0.9559 - loss: 0.1359 - val_accuracy: 0.8339 - val_loss: 0.6371\n",
            "Epoch 10/10\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 102ms/step - accuracy: 0.9598 - loss: 0.1327 - val_accuracy: 0.8340 - val_loss: 0.6476\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate"
      ],
      "metadata": {
        "id": "rAO2Ix9AdpxM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vgg19_scores = model_vgg19.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', vgg19_scores[0])\n",
        "print('Test accuracy:', vgg19_scores[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "1PPl3Ex2drc1",
        "outputId": "c8c1ada4-80b5-46dd-d68d-5ce2dd2addc9"
      },
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.8246 - loss: 0.6707\n",
            "Test loss: 0.674071192741394\n",
            "Test accuracy: 0.8277000188827515\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Variation #2"
      ],
      "metadata": {
        "id": "2HuNN2VreW-9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build and compile the VGG16 model"
      ],
      "metadata": {
        "id": "hnqDkQ9Ceaw-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "# Load VGG16 base\n",
        "base_model_vgg16 = VGG16(include_top=False, weights='imagenet', input_shape=(32, 32, 3))\n",
        "\n",
        "# Create the new model\n",
        "model_vgg16 = Sequential()\n",
        "model_vgg16.add(base_model_vgg16)\n",
        "model_vgg16.add(Flatten())\n",
        "\n",
        "# Add dense layers with dropout\n",
        "model_vgg16.add(Dense(512, activation='relu'))\n",
        "model_vgg16.add(Dropout(0.5))\n",
        "model_vgg16.add(Dense(256, activation='relu'))\n",
        "model_vgg16.add(Dropout(0.3))\n",
        "model_vgg16.add(Dense(10, activation='softmax'))  # Output layer\n",
        "\n",
        "# Compile the model with SGD optimizer\n",
        "model_vgg16.compile(optimizer=SGD(learning_rate=0.001, momentum=0.9),\n",
        "                    loss='categorical_crossentropy',\n",
        "                    metrics=['accuracy'])\n",
        "\n",
        "# Display summary\n",
        "model_vgg16.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "WvtHqQcTeYiK",
        "outputId": "c4f01f87-4e11-4ea9-ee07-77c37d239b1c"
      },
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_23\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_23\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ vgg16 (\u001b[38;5;33mFunctional\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │    \u001b[38;5;34m14,714,688\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_12 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_43 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_18 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_44 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_19 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_45 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m2,570\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ vgg16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,570</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m15,111,242\u001b[0m (57.64 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,111,242</span> (57.64 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m15,111,242\u001b[0m (57.64 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,111,242</span> (57.64 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train"
      ],
      "metadata": {
        "id": "lOnijQW9egeo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history_vgg16 = model_vgg16.fit(\n",
        "    x_train, y_train,\n",
        "    batch_size=64,      # smaller batch\n",
        "    epochs=10,\n",
        "    validation_data=(x_val, y_val),\n",
        "    shuffle=True,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "TGHY1v0aeiCA",
        "outputId": "b2621c74-e6cb-413a-8118-caf7b319cfe5"
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 50ms/step - accuracy: 0.3685 - loss: 1.7436 - val_accuracy: 0.7251 - val_loss: 0.8057\n",
            "Epoch 2/10\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 42ms/step - accuracy: 0.7228 - loss: 0.8370 - val_accuracy: 0.7506 - val_loss: 0.7289\n",
            "Epoch 3/10\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 42ms/step - accuracy: 0.7884 - loss: 0.6473 - val_accuracy: 0.7894 - val_loss: 0.6413\n",
            "Epoch 4/10\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 42ms/step - accuracy: 0.8267 - loss: 0.5284 - val_accuracy: 0.8191 - val_loss: 0.5302\n",
            "Epoch 5/10\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 42ms/step - accuracy: 0.8543 - loss: 0.4371 - val_accuracy: 0.8259 - val_loss: 0.5157\n",
            "Epoch 6/10\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 42ms/step - accuracy: 0.8838 - loss: 0.3630 - val_accuracy: 0.8291 - val_loss: 0.5156\n",
            "Epoch 7/10\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 42ms/step - accuracy: 0.9053 - loss: 0.2968 - val_accuracy: 0.8235 - val_loss: 0.5446\n",
            "Epoch 8/10\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 43ms/step - accuracy: 0.9122 - loss: 0.2589 - val_accuracy: 0.8383 - val_loss: 0.5116\n",
            "Epoch 9/10\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 43ms/step - accuracy: 0.9313 - loss: 0.2043 - val_accuracy: 0.8276 - val_loss: 0.6200\n",
            "Epoch 10/10\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 42ms/step - accuracy: 0.9472 - loss: 0.1694 - val_accuracy: 0.8442 - val_loss: 0.5472\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate"
      ],
      "metadata": {
        "id": "H1Tpt7E-el4f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16_scores = model_vgg16.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', vgg16_scores[0])\n",
        "print('Test accuracy:', vgg16_scores[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "I4HjQir3endY",
        "outputId": "c84cdfd6-4477-498c-cc64-cb3c8e47bece"
      },
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.8409 - loss: 0.5714\n",
            "Test loss: 0.577462375164032\n",
            "Test accuracy: 0.8396000266075134\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Variation #3"
      ],
      "metadata": {
        "id": "lshUs-74eyup"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import MobileNetV2"
      ],
      "metadata": {
        "id": "K-uueCqVe8AN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications import MobileNetV2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator # Corrected import\n",
        "\n",
        "# Load MobileNetV2 base\n",
        "base_model_mobilenet = MobileNetV2(include_top=False, weights='imagenet', input_shape=(32, 32, 3))\n",
        "\n",
        "# Build the new model\n",
        "model_mobilenet = Sequential()\n",
        "model_mobilenet.add(base_model_mobilenet)\n",
        "model_mobilenet.add(Flatten())\n",
        "\n",
        "# Add custom classification layers\n",
        "model_mobilenet.add(Dense(256, activation='relu'))\n",
        "model_mobilenet.add(Dropout(0.5))\n",
        "model_mobilenet.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model using Adam\n",
        "model_mobilenet.compile(optimizer=Adam(learning_rate=0.0001),\n",
        "                        loss='categorical_crossentropy',\n",
        "                        metrics=['accuracy'])\n",
        "\n",
        "# Show model summary\n",
        "model_mobilenet.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "IZKiVANPe5vY",
        "outputId": "482b18c4-83f2-487e-b456-3dbd9dded60d"
      },
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1640626575.py:5: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "  base_model_mobilenet = MobileNetV2(include_top=False, weights='imagenet', input_shape=(32, 32, 3))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_24\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_24\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ mobilenetv2_1.00_224            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │     \u001b[38;5;34m2,257,984\u001b[0m │\n",
              "│ (\u001b[38;5;33mFunctional\u001b[0m)                    │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_13 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_46 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m327,936\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_20 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_47 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m2,570\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ mobilenetv2_1.00_224            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                    │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">327,936</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,570</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,588,490\u001b[0m (9.87 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,588,490</span> (9.87 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,554,378\u001b[0m (9.74 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,554,378</span> (9.74 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m34,112\u001b[0m (133.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">34,112</span> (133.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Augmentation"
      ],
      "metadata": {
        "id": "IlV6ypiYe_1n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a generator for real-time image augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        ")\n",
        "\n",
        "# Fit the generator to training data\n",
        "datagen.fit(x_train)\n"
      ],
      "metadata": {
        "id": "3ZQSzAHNfB1u"
      },
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model using data augmentation"
      ],
      "metadata": {
        "id": "8DoYbc6rfDoU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history_mobilenet = model_mobilenet.fit(\n",
        "    datagen.flow(x_train, y_train, batch_size=128),\n",
        "    validation_data=(x_val, y_val),\n",
        "    steps_per_epoch=len(x_train) // 128,\n",
        "    epochs=10,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "5JMdQxeHfJHV",
        "outputId": "cd23fbb3-bdd6-451c-e68c-0cec67304241"
      },
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 194ms/step - accuracy: 0.1707 - loss: 2.6643 - val_accuracy: 0.1105 - val_loss: 2.5334\n",
            "Epoch 2/10\n",
            "\u001b[1m  1/273\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.3594 - loss: 1.8294"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.3594 - loss: 1.8294 - val_accuracy: 0.1111 - val_loss: 2.5333\n",
            "Epoch 3/10\n",
            "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 84ms/step - accuracy: 0.3741 - loss: 1.7791 - val_accuracy: 0.1835 - val_loss: 2.2742\n",
            "Epoch 4/10\n",
            "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.4219 - loss: 1.5693 - val_accuracy: 0.1841 - val_loss: 2.2778\n",
            "Epoch 5/10\n",
            "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 84ms/step - accuracy: 0.4710 - loss: 1.5132 - val_accuracy: 0.2877 - val_loss: 2.0071\n",
            "Epoch 6/10\n",
            "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.5781 - loss: 1.2620 - val_accuracy: 0.2876 - val_loss: 2.0071\n",
            "Epoch 7/10\n",
            "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 82ms/step - accuracy: 0.5276 - loss: 1.3644 - val_accuracy: 0.3695 - val_loss: 1.8238\n",
            "Epoch 8/10\n",
            "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5625 - loss: 1.2081 - val_accuracy: 0.3703 - val_loss: 1.8235\n",
            "Epoch 9/10\n",
            "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 84ms/step - accuracy: 0.5668 - loss: 1.2478 - val_accuracy: 0.4594 - val_loss: 1.6873\n",
            "Epoch 10/10\n",
            "\u001b[1m273/273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5781 - loss: 1.3806 - val_accuracy: 0.4577 - val_loss: 1.6880\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate"
      ],
      "metadata": {
        "id": "nhN2ecFGfHMk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mobilenet_scores = model_mobilenet.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', mobilenet_scores[0])\n",
        "print('Test accuracy:', mobilenet_scores[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "R-ro0nv1fRHa",
        "outputId": "0332bf13-bf35-483e-cb21-6b49cb19aa94"
      },
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.4613 - loss: 1.6851\n",
            "Test loss: 1.6826046705245972\n",
            "Test accuracy: 0.46639999747276306\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Method        | Base model | Relevant (hyper)parameters                          | Test loss | Test accuracy | Remarks                                     |\n",
        "|---------------|------------|------------------------------------------------------|-----------|----------------|----------------------------------------------|\n",
        "| Baseline      | ResNet50   | SGD, batch_size=128, epochs=10, learning_rate=0.001 | 1.2025    | 0.7526         | Baseline                                     |\n",
        "| Variation #1  | VGG19      | Adam, batch_size=128, epochs=10, learning_rate=0.001| 0.674071192741394 | 0.8277000188827515    | Improved accuracy using deeper VGG19 + Adam |\n",
        "| Variation #2  | VGG16      | SGD, batch_size=64, epochs=10, learning_rate=0.01   | 0.577462375164032 | 0.8396000266075134 | Smaller batch size + higher LR improved results |\n",
        "| Variation #3  | MobileNetV2| Adam, batch_size=128, epochs=10, with data augmentation |1.6826046705245972 | 0.46639999747276306 | Lightweight model + augmentation boosted generalization |\n"
      ],
      "metadata": {
        "id": "7mpccm1sxNz3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this part of the assignment, I explored transfer learning using three different pretrained models on the CIFAR-10 dataset: VGG19, VGG16, and MobileNetV2. I learned that switching base models and tuning hyperparameters like optimizer, learning rate, and batch size can significantly impact accuracy and training stability. VGG19 with the Adam optimizer showed strong baseline performance, while VGG16 with SGD and a smaller batch size helped reduce overfitting. Adding data augmentation with MobileNetV2 improved generalization, even with a lightweight model. Overall, transfer learning made training faster and more efficient, and I now understand how to adapt pretrained models to new image classification tasks.\n"
      ],
      "metadata": {
        "id": "e7gSq0OkfZW_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLi0m9uuKkpD"
      },
      "source": [
        "### Conclusions (10 points)\n",
        "\n",
        "Write your conclusions and make sure to address the issues below:\n",
        "- What have you learned from this assignment?\n",
        "- Which parts were the most fun, time-consuming, enlightening, tedious?\n",
        "- What would you do if you had an additional week to work on this?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_JtoF2cO2RX"
      },
      "source": [
        "What have you learned from this assignment?\n",
        "  - From this assignment, I learned how to build and train neural networks on both MNIST and CIFAR-10 datasets using different architectures like shallow networks, CNNs, and transfer learning. I now understand how important the choice of optimizer, loss function, and base model can be when trying to improve accuracy and reduce overfitting. I also saw the power of transfer learning and how much faster and more effective it is than training from scratch.\n",
        "\n",
        "Which parts were the most fun, time-consuming, enlightening, tedious?\n",
        "  - One of the most interesting but also annoying parts of the assignment was how long model training takes, especially when experimenting with different architectures or increasing the number of epochs. It’s fun to watch the accuracy improve, but waiting for 10+ epochs to finish over and over gets tedious quickly, especially when the changes don’t always improve the model. Sometimes I would run something for 10 minutes just to realize the accuracy barely changed. But it is satisfying when the training pays off and you finally get a better result.\n",
        "\n",
        "What would you do if you had an additional week to work on this?\n",
        "  - If I had an extra week, I’d focus more on optimizing training time, maybe trying smaller models, reducing epochs with early stopping, or experimenting with faster optimizers and learning rate schedules. I’d also try testing these models on a different dataset to see how well they generalize beyond CIFAR-10.\n"
      ]
    }
  ]
}